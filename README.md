# transformer
Exploring how transformers work.
* Multi-head attention
* Sin position encoding
* Byte-pair encoding
* Transformer encoder and decoder layers
* Translator and GPT models

## Sources

### Transformer
* Andrej Karpathy: https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy
* Arjun Sarkar: https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb
* Attention Is All You Need: https://arxiv.org/pdf/1706.03762

### Byte-Pair Encoding
* Andrej Karpathy: https://www.youtube.com/watch?v=zduSFxRajkE&ab_channel=AndrejKarpathy
* Andrej Karpathy: https://github.com/karpathy/minbpe/tree/master
* Wikipedia: https://en.wikipedia.org/wiki/Byte_pair_encoding

### Neural Machine Translation
* Keras: https://keras.io/examples/nlp/neural_machine_translation_with_transformer/
